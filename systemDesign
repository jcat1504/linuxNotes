## Fundamentals of System Design

## SYSTEM DESIGN PRINCIPLES 
**How do we architect a system that supports the functionality and requirements of system in the best way possible?**
- Scalability: Handle additional load and will operate efficiently
- Reliability: Perform function as expected, tolerate user mistakes, good for required use case, prevents unauthorized access/abuse
- Availability: perform its functionality(uptime/total time). Availability does not imply reliability 
- Efficiency: Perform functionality quickly. Latency, response time, bandwidth
- Maintainability: easy to operate smoothly, simple to understand, easy to modify for cases

**TRADEOFFS**: Helpful to understand how each component, algorithms, and architectural designs work.
  - Works independently 
  - Compares to other tools that perform similarily 
 
 ## LOAD BALANCERS 
 - Type of server that distributes incoming web traffic across multiple backend servers
  - Allow applications to scale up or down with demand, achieve higher availability and efficiently utilize server capacity 
  - Horizontal scaling: Add more servers to the system 
    - When one or more servers can be used to serve a request, it becomes necessary to decide which server to send request to
- Good load balancer will efficiently distribute incoming traffic to maximize the systems capacity utilization and minimize queueing time

** Can distribute traffic**:
- Round Robin: servers designed in repeating sequence, so that next server assigned is guaranteed to be least recently used 
- Least Connections: Assigns the server currently handling the fewest number of requests 
- Consistent Hashing: Similar to database sharding, server can be assigned consistently based on IP address or URL
- engineers don't implement load balancers, they use industry standard reverse proxy

**WHEN TO USE LOAD BALANCERS**: When you think the system you're designing would benefit from increased capacity/redundency 
- Advantages: 
  - Scalability: easy to scale up/down by adding/removing servers
  - Reliability: Provide redundancy + minimize downtime by automatically detaching + replacing unhealthy servers
- Considerations: 
  - Bottlenecks: can be single point of failure 
  - User session: some user requests can be served from different backends unless load balancer is configurered otherwise 
  - Longer deploys: deploying ner server versions can take longer and require more machines
 
 ###CACHE
 - Data storage technique that plays a big role in designing scalable internet applications. Stores and retrieves data quickly for future use, 
 enabling faster response times and decreasing loads for other parts of system
 - reduce repeated calculations database queries or requests to other services serving more traffic volume
 HOW IT WORKS:
 - In memory application cache
 - distributed in-memory cache
 - database cache
 - file system cache
 
- Why not cache everything? well there are costs and accuracy to consider. 
Caching policy: helps the cache free up space for the most relevant data that will be needed in the future
  -FIFO
  - Least recently used(LRU)
  - Least frequently used(LFU)
 
 
 ##CONTENT DELIVERY NETWORKS(CDN)
 - a modern and popular solution for minimizing request latency when fetching static assets from a server. An ideal CDN is compoased of a group of servers that are 
 spread out globally, so that no matter how you are from your origin server, there is always a CDN server closeby.
 -so instead of fetching static files from origin server, users can fetch cached copies from cdn more quickly
 
**HOW DO CDNS WORK?** - Push and Pull CDNS
- Push: responsibility of engineers to push new/updated files to the cdn, which would then propagate them to all of the cdn server caches
- Pull : the server cache is lazily updated: when a user sends a static asset request to the cdn server and doesn't have it, it'll fetch the asset from the origin
populate its cache with asset then send asset to the user.

##SQL VS NOSQL
SQL:
- Relationships: relational databases, allows easy querying on relationships between data among multiple tables. They are defined using primary and foreign key columns.
Table relationships are important for organizing and structuring a lot of different data
-Powerful for fetching data
- Structured Data: data is structured using schemas that define the columns and tables in a database. 
- Acid: (Atomicity, Consistency, Isolation, Durability) compliant, and they ensure that by supporting transactions. 
*CONS*
-Take up more time to set up compared to nosql database. they are not effective for storying and querying unstructured data
- Difficult to scale horizontally. 

NoSQL:
- do not support table relationships and data usually stored in documents or as key-value pairs. so it is a bit more flexible and simpler to set up
- without table relationships, nosql database can be sharded across different data stores, allowing for distributed databases. this makes horizontal scaling much easier
and very large amounts of data can be stored without having to purchase a single, expensive server. hashing and consistent hashing are very important techniques
for determining which shard(s) to route application queries to. 


##CAP THEOREM
CAP: Consistency, Availability, Partition tolerance
- A network partition is a temporary network failure between nodes. This means being able to keep the nodes in a distributed database running even when there are network partitions
This means that in a distributed db, you ensure consistency or availability in case of a network partition

CONSISTENCY
- In a scenario where there is a network partition, any write requests between node a and b would be rejected
this is to ensure that both nodes remain the same

AVAILABILITY
-in a db that prioritizes availability, its ok to have inconsistent data between nodes as long as we prioritize the ones that successfully complete requests sent to them
-available db also tend to have eventual consistency, eventually all nodes will sync when network partition is resolved

When should Consistency or Availability be prioritized?
- If working with data that needs to be up to date: prioritize CONSISTENCY
- If its ok for queried data to be out of date: AVAILABILITY 

-in the real world, when we talk about databases that prioritize consistency, we usually refer to db that are eventually consistent with very short noticeable lag time b/t nodes

##DATABASE SHARDING
- Process of breaking up large tables into horizontal data partitions, each of which contains a subset of the whole table and
putting up each partition on a separate db server
- this is because as data size increases, traditional database systems run into bottlenecks on cpu, memory or disk usage

SHARDING TECHNIQUES
-Geo based sharding: data is partitioned to a static location chosen, such as user's location when their acct was created
this is to reduce latency 
-Range based sharding: divides data based on ranges of key value, like choosing first letter of user's name
it is simple but can lead to uneven splits across data partitions
-Hash based: data based on key value then using hash val to compute partition. a good hash algo will distribute data evenly across partitions
but it is likely to assign related rows to diff partitions, so server can't enhance performance by trying to predict/pre-load future queries

ADVANTAGES OF SHARDING
-Sharding allows a system to scale out as the size of data increases. It allows the application to deal with a larger amount of data than can be done using a traditional RDBMS.
-Having a smaller set of data in each shard also means that the indexes on that data are smaller, which result in faster query performance.
-If an unplanned outage takes down a shard, the majority of the system remains accessible while that shard is restored. Downtime doesnâ€™t take out the whole system.
-Smaller amounts of data in each shard mean that the nodes can run on commodity hardware, and do not require expensive high-end hardware to deliver an acceptable performance.

DISADVANTAGES
-Not all data is amenable to sharding.
-Foreign key relationships can only be maintained within a single shard.
-Manual sharding can be very complex and can lead to hotspots.
-Because each shard runs on a separate database server, some types of cross-shard queries (such as table joins) are either very expensive, or not possible.
-Once sharding has been set up, it is very hard (if not impossible) on some systems to undo sharding or to change the shard key.
-Each shard is a live production database server, so needs to ensure high-availability (via replication or other techniques). This increases the operational cost compared to a single RDBMS.

##How Do Computers Handle Memory Management?
- Memory management deals with how the system allocates and frees up memory during the execution of a program
- most older programming languages(C or C++) dont have any kind of automatic memory management
- Stack and Heap 
-Management on stack is automatic on all platforms
- A critical requirement for managing memory effectively is that each allocation be matched by exactly one de-allocation


**GARBAGE COLLECTION**
-When the system detects that a program is running low on memory, it pauses execution of the program and runs a Garbage Collector (GC).
1. Marks all the in use memory thats reachable from current program state
2. compacts the heap by moving all reachable memory into the beginning of the heap and updates references to the new locations
3. releases unreachable memory

 **Automatic Reference Counting (ARC)**
 -An alternative approach is to maintain a reference count to each piece of allocated memory, and update it as the program executes



