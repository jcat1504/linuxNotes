## Fundamentals of System Design

## SYSTEM DESIGN PRINCIPLES 
**How do we architect a system that supports the functionality and requirements of system in the best way possible?**
- Scalability: Handle additional load and will operate efficiently
- Reliability: Perform function as expected, tolerate user mistakes, good for required use case, prevents unauthorized access/abuse
- Availability: perform its functionality(uptime/total time). Availability does not imply reliability 
- Efficiency: Perform functionality quickly. Latency, response time, bandwidth
- Maintainability: easy to operate smoothly, simple to understand, easy to modify for cases

**TRADEOFFS**: Helpful to understand how each component, algorithms, and architectural designs work.
  - Works independently 
  - Compares to other tools that perform similarily 
 
 ## LOAD BALANCERS 
 - Type of server that distributes incoming web traffic across multiple backend servers
  - Allow applications to scale up or down with demand, achieve higher availability and efficiently utilize server capacity 
  - Horizontal scaling: Add more servers to the system 
    - When one or more servers can be used to serve a request, it becomes necessary to decide which server to send request to
- Good load balancer will efficiently distribute incoming traffic to maximize the systems capacity utilization and minimize queueing time

** Can distribute traffic**:
- Round Robin: servers designed in repeating sequence, so that next server assigned is guaranteed to be least recently used 
- Least Connections: Assigns the server currently handling the fewest number of requests 
- Consistent Hashing: Similar to database sharding, server can be assigned consistently based on IP address or URL
- engineers don't implement load balancers, they use industry standard reverse proxy

**WHEN TO USE LOAD BALANCERS**: When you think the system you're designing would benefit from increased capacity/redundency 
- Advantages: 
  - Scalability: easy to scale up/down by adding/removing servers
  - Reliability: Provide redundancy + minimize downtime by automatically detaching + replacing unhealthy servers
- Considerations: 
  - Bottlenecks: can be single point of failure 
  - User session: some user requests can be served from different backends unless load balancer is configurered otherwise 
  - Longer deploys: deploying ner server versions can take longer and require more machines
 
 ### CACHE ###
 - Data storage technique that plays a big role in designing scalable internet applications. Stores and retrieves data quickly for future use, 
 enabling faster response times and decreasing loads for other parts of system
 - reduce repeated calculations database queries or requests to other services serving more traffic volume
 HOW IT WORKS:
 - In memory application cache
 - distributed in-memory cache
 - database cache
 - file system cache
 
- Why not cache everything? well there are costs and accuracy to consider. 
Caching policy: helps the cache free up space for the most relevant data that will be needed in the future
  -FIFO
  - Least recently used(LRU)
  - Least frequently used(LFU)
 
